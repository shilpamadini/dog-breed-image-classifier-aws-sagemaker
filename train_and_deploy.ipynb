{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Image Classification MLOps using Amazon Sagemaker\n",
    "This notebook lists all the steps that you need to complete the complete this project. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-04T00:03:57.133517Z",
     "iopub.status.busy": "2025-11-04T00:03:57.133235Z",
     "iopub.status.idle": "2025-11-04T00:04:00.813552Z",
     "shell.execute_reply": "2025-11-04T00:04:00.812220Z",
     "shell.execute_reply.started": "2025-11-04T00:03:57.133495Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting smdebug\n",
      "  Using cached smdebug-1.0.34-py2.py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting protobuf<=3.20.3,>=3.20.0 (from smdebug)\n",
      "  Using cached protobuf-3.20.3-py2.py3-none-any.whl.metadata (720 bytes)\n",
      "Requirement already satisfied: numpy>=1.16.0 in /opt/conda/lib/python3.12/site-packages (from smdebug) (1.26.4)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.12/site-packages (from smdebug) (24.2)\n",
      "Requirement already satisfied: boto3>=1.10.32 in /opt/conda/lib/python3.12/site-packages (from smdebug) (1.37.1)\n",
      "Collecting pyinstrument==3.4.2 (from smdebug)\n",
      "  Using cached pyinstrument-3.4.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting pyinstrument-cext>=0.2.2 (from pyinstrument==3.4.2->smdebug)\n",
      "  Using cached pyinstrument_cext-0.2.4-cp312-cp312-linux_x86_64.whl\n",
      "Requirement already satisfied: botocore<1.38.0,>=1.37.1 in /opt/conda/lib/python3.12/site-packages (from boto3>=1.10.32->smdebug) (1.37.1)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/conda/lib/python3.12/site-packages (from boto3>=1.10.32->smdebug) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.12.0,>=0.11.0 in /opt/conda/lib/python3.12/site-packages (from boto3>=1.10.32->smdebug) (0.11.3)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /opt/conda/lib/python3.12/site-packages (from botocore<1.38.0,>=1.37.1->boto3>=1.10.32->smdebug) (2.9.0.post0)\n",
      "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /opt/conda/lib/python3.12/site-packages (from botocore<1.38.0,>=1.37.1->boto3>=1.10.32->smdebug) (1.26.19)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.12/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.38.0,>=1.37.1->boto3>=1.10.32->smdebug) (1.17.0)\n",
      "Using cached smdebug-1.0.34-py2.py3-none-any.whl (280 kB)\n",
      "Using cached pyinstrument-3.4.2-py2.py3-none-any.whl (83 kB)\n",
      "Using cached protobuf-3.20.3-py2.py3-none-any.whl (162 kB)\n",
      "Installing collected packages: pyinstrument-cext, pyinstrument, protobuf, smdebug\n",
      "\u001b[2K  Attempting uninstall: protobuf\n",
      "\u001b[2K    Found existing installation: protobuf 5.28.3\n",
      "\u001b[2K    Uninstalling protobuf-5.28.3:\n",
      "\u001b[2K      Successfully uninstalled protobuf-5.28.3\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4/4\u001b[0m [smdebug]m3/4\u001b[0m [smdebug]]\n",
      "\u001b[1A\u001b[2KSuccessfully installed protobuf-3.20.3 pyinstrument-3.4.2 pyinstrument-cext-0.2.4 smdebug-1.0.34\n"
     ]
    }
   ],
   "source": [
    "\n",
    "!pip install smdebug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-04T23:01:40.287226Z",
     "iopub.status.busy": "2025-11-04T23:01:40.286916Z",
     "iopub.status.idle": "2025-11-04T23:01:40.792958Z",
     "shell.execute_reply": "2025-11-04T23:01:40.791065Z",
     "shell.execute_reply.started": "2025-11-04T23:01:40.287194Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Role: arn:aws:iam::106660882488:role/service-role/AmazonSageMaker-ExecutionRole-20251027T142948\n",
      "Default S3 bucket: sagemaker-us-east-1-106660882488\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "import os, time, json\n",
    "import boto3\n",
    "from sagemaker.pytorch import PyTorch\n",
    "from sagemaker.tuner import HyperparameterTuner, ContinuousParameter, IntegerParameter\n",
    "from sagemaker.inputs import TrainingInput\n",
    "from sagemaker.debugger import ProfilerRule, FrameworkProfile, ProfilerConfig, rule_configs, DebuggerHookConfig, CollectionConfig, Rule\n",
    "\n",
    "sess = sagemaker.Session()\n",
    "role = sagemaker.get_execution_role()\n",
    "\n",
    "print(\"Role:\", role)\n",
    "print(\"Default S3 bucket:\", sess.default_bucket())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "This project uses the Dog Breed Classification dataset provided in the Udacity classroom. The dataset contains images from 133 different dog breeds, covering a wide range of sizes, coat types, and geographic origins. The dataset is already split into training, validation, and testing sets, which supports a clean and reproducible ML workflow. Images vary in lighting, pose, and background, making the classification task more realistic and challenging. This variety encourages strong generalization and helps evaluate the effectiveness of transfer learning when adapting a pre trained model like ResNet to a multi class image classification problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-04T20:06:11.279902Z",
     "iopub.status.busy": "2025-11-04T20:06:11.279619Z"
    }
   },
   "outputs": [],
   "source": [
    "# Command to download and unzip data\n",
    "# Uncomment and run the below two lines of code only the first time when you want to download and upload the data to s3\n",
    "\n",
    "#!wget https://s3-us-west-1.amazonaws.com/udacity-aind/dog-project/dogImages.zip\n",
    "#!unzip dogImages.zip\n",
    "\n",
    "\n",
    "# Upload Data to S3\n",
    "# Run this cell only the first time, to upload the data once.\n",
    "LOCAL_DIR = 'dogImages'\n",
    "S3_BUCKET = sess.default_bucket()\n",
    "DATA_PREFIX = \"dogimages\"\n",
    "input_data_path = sess.upload_data(path=LOCAL_DIR, bucket=S3_BUCKET, key_prefix=DATA_PREFIX)\n",
    "\n",
    "print(f\"input data path: {input_data_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-04T20:18:31.144498Z",
     "iopub.status.busy": "2025-11-04T20:18:31.143893Z",
     "iopub.status.idle": "2025-11-04T20:18:31.150437Z",
     "shell.execute_reply": "2025-11-04T20:18:31.149242Z",
     "shell.execute_reply.started": "2025-11-04T20:18:31.144461Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output path: s3://sagemaker-us-east-1-106660882488/dogimages/outputs/20251104-201831\n",
      "code location: s3://sagemaker-us-east-1-106660882488/dogimages/code/20251104-201831\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Set Input and Output path on S3 for the project\n",
    "train = f\"s3://{S3_BUCKET}/{DATA_PREFIX}/train\"\n",
    "valid   = f\"s3://{S3_BUCKET}/{DATA_PREFIX}/valid\"\n",
    "test = f\"s3://{S3_BUCKET}/{DATA_PREFIX}/valid\"\n",
    "\n",
    "timestamp = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "output_path = f\"s3://{S3_BUCKET}/{DATA_PREFIX}/outputs/{timestamp}\"\n",
    "code_location = f\"s3://{S3_BUCKET}/{DATA_PREFIX}/code/{timestamp}\"\n",
    "\n",
    "print(f\"output path: {output_path}\")\n",
    "print(f\"code location: {code_location}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning\n",
    "This section focuses on fine-tuning a pretrained ResNet-50 using SageMaker Hyperparameter Optimization (HPO).\n",
    "The goal is to systematically explore parameter combinations that improve validation performance.\n",
    "I use hpo.py as the training entry script so SageMaker can run multiple jobs in parallel with different settings.\n",
    "Key hyperparameters tuned include learning rate, batch size, and epochs.\n",
    "Learning rate controls convergence speed, batch size affects stability and generalization, and epochs balance training time versus overfitting.\n",
    "I chose these ranges—learning rate (1e-4 to 1e-2), batch size (8–32), and epochs (3–10)—to stay within GPU memory and runtime limits.\n",
    "The objective metric for HPO is validation loss (val_loss), since it measures generalization without leaking test data.\n",
    "SageMaker automatically tracks printed metrics (val_loss, val_accuracy, test_loss, test_accuracy) from the training script.\n",
    "All training artifacts and logs are stored in versioned S3 paths to ensure full reproducibility.\n",
    "After tuning completes, the best model and its optimal hyperparameters are retrieved for final evaluation on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-04T20:18:35.116056Z",
     "iopub.status.busy": "2025-11-04T20:18:35.115754Z",
     "iopub.status.idle": "2025-11-04T20:18:35.121266Z",
     "shell.execute_reply": "2025-11-04T20:18:35.120175Z",
     "shell.execute_reply.started": "2025-11-04T20:18:35.116033Z"
    }
   },
   "outputs": [],
   "source": [
    "#Declare your HP ranges, metrics etc.\n",
    "hyperparameter_ranges = {\n",
    "    \"learning_rate\": ContinuousParameter(1e-4, 1e-2),  \n",
    "    \"batch_size\": IntegerParameter(8, 32),             \n",
    "    \"epochs\": IntegerParameter(3, 10),                 \n",
    "}\n",
    "\n",
    "metric_definitions = [\n",
    "    {\"Name\": \"val_loss\",       \"Regex\": r\"val_loss=([0-9.+-eE]+);\"},\n",
    "    {\"Name\": \"test_loss\",      \"Regex\": r\"test_loss=([0-9.+-eE]+);\"},\n",
    "    {\"Name\": \"test_accuracy\",  \"Regex\": r\"test_accuracy=([0-9.+-eE]+);\"},\n",
    "    {\"Name\": \"train_loss\",     \"Regex\": r\"train_loss=([0-9.+-eE]+);\"},\n",
    "]\n",
    "\n",
    "objective_metric_name = \"val_loss\"\n",
    "objective_type = \"Minimize\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-04T20:18:44.626748Z",
     "iopub.status.busy": "2025-11-04T20:18:44.626429Z",
     "iopub.status.idle": "2025-11-04T20:18:44.687698Z",
     "shell.execute_reply": "2025-11-04T20:18:44.686141Z",
     "shell.execute_reply.started": "2025-11-04T20:18:44.626725Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['val_loss', 'test_loss', 'test_accuracy', 'train_loss']\n"
     ]
    }
   ],
   "source": [
    "# Create estimators for your HPs\n",
    "\n",
    "INSTANCE_TYPE = \"ml.g4dn.xlarge\"  \n",
    "\n",
    "estimator = PyTorch(\n",
    "    entry_point=\"hpo.py\",\n",
    "    source_dir=\".\",\n",
    "    role=role,\n",
    "    framework_version=\"1.13\",\n",
    "    py_version=\"py39\",\n",
    "    instance_type=INSTANCE_TYPE,\n",
    "    instance_count=1,\n",
    "    output_path=output_path,         \n",
    "    code_location=code_location,     \n",
    "    metric_definitions=metric_definitions,\n",
    "    hyperparameters={\n",
    "        \"num_classes\": 133, # Dataset consists of 133 classes\n",
    "        \"image_size\": 224, # Input requirement for the pre trained ResNet-50 model\n",
    "        \"device\": \"cuda\",            \n",
    "    },\n",
    ")\n",
    "\n",
    "tuner = HyperparameterTuner(\n",
    "    estimator=estimator,\n",
    "    metric_definitions=metric_definitions,\n",
    "    early_stopping_type = \"Auto\",\n",
    "    objective_metric_name=\"val_loss\",\n",
    "    hyperparameter_ranges=hyperparameter_ranges,\n",
    "    objective_type=\"Minimize\",\n",
    "    max_jobs=8,            \n",
    "    max_parallel_jobs=2,   \n",
    ")\n",
    "\n",
    "print([m[\"Name\"] for m in estimator.metric_definitions])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-04T20:46:36.723068Z",
     "iopub.status.busy": "2025-11-04T20:46:36.722770Z",
     "iopub.status.idle": "2025-11-04T20:46:36.763281Z",
     "shell.execute_reply": "2025-11-04T20:46:36.762390Z",
     "shell.execute_reply.started": "2025-11-04T20:46:36.723046Z"
    }
   },
   "outputs": [],
   "source": [
    "single = PyTorch(\n",
    "    entry_point=\"hpo.py\",           \n",
    "    source_dir=\".\",                 \n",
    "    role=role,                      \n",
    "    framework_version=\"1.13\",\n",
    "    py_version=\"py39\",\n",
    "    instance_type=\"ml.g4dn.xlarge\", \n",
    "    instance_count=1,\n",
    "    output_path=output_path,\n",
    "    code_location=code_location,\n",
    "    metric_definitions=metric_definitions,\n",
    "    hyperparameters={\n",
    "        \"num_classes\": 133, # Dataset consists of 133 classes\n",
    "        \"image_size\": 224, # Input requirement for the pre trained ResNet-50 model\n",
    "        \"device\": \"cuda\",            \n",
    "    },\n",
    ")\n",
    "\n",
    "inputs = {\n",
    "    \"training\": TrainingInput(s3_data=input_data_path, distribution=\"FullyReplicated\")\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-04T20:46:39.595306Z",
     "iopub.status.busy": "2025-11-04T20:46:39.595010Z",
     "iopub.status.idle": "2025-11-04T21:13:23.418102Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.telemetry.telemetry_logging:SageMaker Python SDK will collect telemetry to help us better understand our user's needs, diagnose issues, and deliver additional features.\n",
      "To opt out of telemetry, please disable via TelemetryOptOut parameter in SDK defaults config. For more information, refer to https://sagemaker.readthedocs.io/en/stable/overview.html#configuring-and-using-defaults-with-the-sagemaker-python-sdk.\n",
      "INFO:sagemaker.image_uris:image_uri is not presented, retrieving image_uri based on instance_type, framework etc.\n",
      "INFO:sagemaker.image_uris:image_uri is not presented, retrieving image_uri based on instance_type, framework etc.\n",
      "INFO:sagemaker:Creating training-job with name: pytorch-training-2025-11-04-20-46-39-624\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-04 20:48:15 Starting - Starting the training job\n",
      "2025-11-04 20:48:15 Pending - Training job waiting for capacity......\n",
      "2025-11-04 20:49:10 Pending - Preparing the instances for training...\n",
      "2025-11-04 20:49:44 Downloading - Downloading input data......................\n",
      "2025-11-04 20:53:47 Training - Training image download completed. Training in progress...\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.9/site-packages/paramiko/pkey.py:100: CryptographyDeprecationWarning: TripleDES has been moved to cryptography.hazmat.decrepit.ciphers.algorithms.TripleDES and will be removed from this module in 48.0.0.\n",
      "  \"cipher\": algorithms.TripleDES,\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.9/site-packages/paramiko/transport.py:259: CryptographyDeprecationWarning: TripleDES has been moved to cryptography.hazmat.decrepit.ciphers.algorithms.TripleDES and will be removed from this module in 48.0.0.\n",
      "  \"class\": algorithms.TripleDES,\u001b[0m\n",
      "\u001b[34m2025-11-04 20:54:01,131 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2025-11-04 20:54:01,156 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2025-11-04 20:54:01,171 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2025-11-04 20:54:01,180 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2025-11-04 20:54:19,730 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2025-11-04 20:54:19,792 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2025-11-04 20:54:19,853 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2025-11-04 20:54:19,880 sagemaker-training-toolkit INFO     Invoking user script\u001b[0m\n",
      "\u001b[34mTraining Env:\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"training\": \"/opt/ml/input/data/training\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"current_instance_group\": \"homogeneousCluster\",\n",
      "    \"current_instance_group_hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"current_instance_type\": \"ml.g4dn.xlarge\",\n",
      "    \"distribution_hosts\": [],\n",
      "    \"distribution_instance_groups\": [],\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"device\": \"cuda\",\n",
      "        \"image_size\": 224,\n",
      "        \"num_classes\": 133\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"training\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"instance_groups\": [\n",
      "        \"homogeneousCluster\"\n",
      "    ],\n",
      "    \"instance_groups_dict\": {\n",
      "        \"homogeneousCluster\": {\n",
      "            \"instance_group_name\": \"homogeneousCluster\",\n",
      "            \"instance_type\": \"ml.g4dn.xlarge\",\n",
      "            \"hosts\": [\n",
      "                \"algo-1\"\n",
      "            ]\n",
      "        }\n",
      "    },\n",
      "    \"is_hetero\": false,\n",
      "    \"is_master\": true,\n",
      "    \"is_modelparallel_enabled\": null,\n",
      "    \"is_smddpmprun_installed\": true,\n",
      "    \"is_smddprun_installed\": true,\n",
      "    \"job_name\": \"pytorch-training-2025-11-04-20-46-39-624\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-1-106660882488/dogimages/code/20251104-201831/pytorch-training-2025-11-04-20-46-39-624/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"hpo\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 4,\n",
      "    \"num_gpus\": 1,\n",
      "    \"num_neurons\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"current_instance_type\": \"ml.g4dn.xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.g4dn.xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\",\n",
      "        \"topology\": null\n",
      "    },\n",
      "    \"user_entry_point\": \"hpo.py\"\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mEnvironment variables:\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"device\":\"cuda\",\"image_size\":224,\"num_classes\":133}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=hpo.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.g4dn.xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g4dn.xlarge\"}],\"network_interface_name\":\"eth0\",\"topology\":null}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"training\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_TYPE=ml.g4dn.xlarge\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_GROUP=homogeneousCluster\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_GROUP_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_INSTANCE_GROUPS=[\"homogeneousCluster\"]\u001b[0m\n",
      "\u001b[34mSM_INSTANCE_GROUPS_DICT={\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g4dn.xlarge\"}}\u001b[0m\n",
      "\u001b[34mSM_DISTRIBUTION_INSTANCE_GROUPS=[]\u001b[0m\n",
      "\u001b[34mSM_IS_HETERO=false\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=hpo\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=4\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=1\u001b[0m\n",
      "\u001b[34mSM_NUM_NEURONS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-east-1-106660882488/dogimages/code/20251104-201831/pytorch-training-2025-11-04-20-46-39-624/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"training\":\"/opt/ml/input/data/training\"},\"current_host\":\"algo-1\",\"current_instance_group\":\"homogeneousCluster\",\"current_instance_group_hosts\":[\"algo-1\"],\"current_instance_type\":\"ml.g4dn.xlarge\",\"distribution_hosts\":[],\"distribution_instance_groups\":[],\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"device\":\"cuda\",\"image_size\":224,\"num_classes\":133},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"instance_groups\":[\"homogeneousCluster\"],\"instance_groups_dict\":{\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g4dn.xlarge\"}},\"is_hetero\":false,\"is_master\":true,\"is_modelparallel_enabled\":null,\"is_smddpmprun_installed\":true,\"is_smddprun_installed\":true,\"job_name\":\"pytorch-training-2025-11-04-20-46-39-624\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-106660882488/dogimages/code/20251104-201831/pytorch-training-2025-11-04-20-46-39-624/source/sourcedir.tar.gz\",\"module_name\":\"hpo\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":1,\"num_neurons\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.g4dn.xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g4dn.xlarge\"}],\"network_interface_name\":\"eth0\",\"topology\":null},\"user_entry_point\":\"hpo.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--device\",\"cuda\",\"--image_size\",\"224\",\"--num_classes\",\"133\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAINING=/opt/ml/input/data/training\u001b[0m\n",
      "\u001b[34mSM_HP_DEVICE=cuda\u001b[0m\n",
      "\u001b[34mSM_HP_IMAGE_SIZE=224\u001b[0m\n",
      "\u001b[34mSM_HP_NUM_CLASSES=133\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python39.zip:/opt/conda/lib/python3.9:/opt/conda/lib/python3.9/lib-dynload:/opt/conda/lib/python3.9/site-packages\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.9 hpo.py --device cuda --image_size 224 --num_classes 133\u001b[0m\n",
      "\u001b[34m2025-11-04 20:54:20,200 sagemaker-training-toolkit INFO     Exceptions not imported for SageMaker TF as Tensorflow is not installed.\u001b[0m\n",
      "\u001b[34m[2025-11-04 20:54:21.966 algo-1:75 INFO utils.py:28] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[2025-11-04 20:54:22.542 algo-1:75 INFO profiler_config_parser.py:111] User has disabled profiler.\u001b[0m\n",
      "\u001b[34mModel creation for fine-tuning.\u001b[0m\n",
      "\u001b[34mINFO:__main__:Model creation for fine-tuning.\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\u001b[0m\n",
      "\u001b[34mDownloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\u001b[0m\n",
      "\u001b[34m0%|          | 0.00/97.8M [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34m39%|███▉      | 38.4M/97.8M [00:00<00:00, 402MB/s]\u001b[0m\n",
      "\u001b[34m78%|███████▊  | 76.7M/97.8M [00:00<00:00, 388MB/s]\u001b[0m\n",
      "\u001b[34m100%|██████████| 97.8M/97.8M [00:00<00:00, 393MB/s]\u001b[0m\n",
      "\u001b[34mModel creation complete.\u001b[0m\n",
      "\u001b[34mINFO:__main__:Model creation complete.\u001b[0m\n",
      "\u001b[34m[2025-11-04 20:54:25.267 algo-1:75 INFO json_config.py:92] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m[2025-11-04 20:54:25.268 algo-1:75 INFO hook.py:206] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[34m[2025-11-04 20:54:25.268 algo-1:75 INFO hook.py:259] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m[2025-11-04 20:54:25.268 algo-1:75 INFO state_store.py:77] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\u001b[0m\n",
      "\u001b[34m[2025-11-04 20:54:25.283 algo-1:75 INFO hook.py:561] name:fc.weight count_params:272384\u001b[0m\n",
      "\u001b[34m[2025-11-04 20:54:25.284 algo-1:75 INFO hook.py:561] name:fc.bias count_params:133\u001b[0m\n",
      "\u001b[34m[2025-11-04 20:54:25.284 algo-1:75 INFO hook.py:563] Total Trainable Params: 272517\u001b[0m\n",
      "\u001b[34mSageMaker Debugger hook registered.\u001b[0m\n",
      "\u001b[34mINFO:__main__:SageMaker Debugger hook registered.\u001b[0m\n",
      "\u001b[34mData loader creation start\u001b[0m\n",
      "\u001b[34mINFO:__main__:Data loader creation start\u001b[0m\n",
      "\u001b[34mData loader creation complete\u001b[0m\n",
      "\u001b[34mINFO:__main__:Data loader creation complete\u001b[0m\n",
      "\u001b[34mINFO:__main__:Data loader creation start\u001b[0m\n",
      "\u001b[34mData loader creation start\u001b[0m\n",
      "\u001b[34mData loader creation complete\u001b[0m\n",
      "\u001b[34mINFO:__main__:Data loader creation complete\u001b[0m\n",
      "\u001b[34mINFO:__main__:Data loader creation start\u001b[0m\n",
      "\u001b[34mINFO:__main__:Data loader creation complete\u001b[0m\n",
      "\u001b[34mINFO:__main__:Training start.\u001b[0m\n",
      "\u001b[34mData loader creation start\u001b[0m\n",
      "\u001b[34mData loader creation complete\u001b[0m\n",
      "\u001b[34mTraining start.\u001b[0m\n",
      "\u001b[34mTraining:   0%|          | 0/10 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34m[2025-11-04 20:54:25.775 algo-1:75 INFO hook.py:427] Monitoring the collections: losses\u001b[0m\n",
      "\u001b[34m[2025-11-04 20:54:25.777 algo-1:75 INFO hook.py:491] Hook is writing from the hook with pid: 75\u001b[0m\n",
      "\u001b[34mEpoch 0: train_loss = 1049.019620\u001b[0m\n",
      "\u001b[34mval_loss=45.925154;\u001b[0m\n",
      "\u001b[34mTraining:  10%|█         | 1/10 [01:58<17:48, 118.75s/it]\u001b[0m\n",
      "\u001b[34mEpoch 1: train_loss = 561.998594\u001b[0m\n",
      "\u001b[34mval_loss=39.235192;\u001b[0m\n",
      "\u001b[34mTraining:  20%|██        | 2/10 [03:46<14:59, 112.42s/it]\u001b[0m\n",
      "\u001b[34mEpoch 2: train_loss = 498.012780\u001b[0m\n",
      "\u001b[34mval_loss=31.337488;\u001b[0m\n",
      "\u001b[34mTraining:  30%|███       | 3/10 [05:35<12:53, 110.56s/it]\u001b[0m\n",
      "\u001b[34mEpoch 3: train_loss = 483.897473\u001b[0m\n",
      "\u001b[34mval_loss=31.633992;\u001b[0m\n",
      "\u001b[34mTraining:  40%|████      | 4/10 [07:23<10:58, 109.81s/it]\u001b[0m\n",
      "\u001b[34mEpoch 4: train_loss = 445.963665\u001b[0m\n",
      "\u001b[34mval_loss=31.647291;\u001b[0m\n",
      "\u001b[34mTraining:  50%|█████     | 5/10 [09:12<09:06, 109.34s/it]\u001b[0m\n",
      "\u001b[34mEpoch 5: train_loss = 439.390464\u001b[0m\n",
      "\u001b[34mval_loss=28.862190;\u001b[0m\n",
      "\u001b[34mTraining:  60%|██████    | 6/10 [11:00<07:15, 108.94s/it]\u001b[0m\n",
      "\u001b[34mEpoch 6: train_loss = 451.040339\u001b[0m\n",
      "\u001b[34mval_loss=34.784073;\u001b[0m\n",
      "\u001b[34mTraining:  70%|███████   | 7/10 [12:48<05:25, 108.59s/it]\u001b[0m\n",
      "\u001b[34mEpoch 7: train_loss = 426.908292\u001b[0m\n",
      "\u001b[34mval_loss=28.415440;\u001b[0m\n",
      "\u001b[34mTraining:  80%|████████  | 8/10 [14:37<03:37, 108.79s/it]\u001b[0m\n",
      "\u001b[34mEpoch 8: train_loss = 407.606781\u001b[0m\n",
      "\u001b[34mval_loss=27.061589;\u001b[0m\n",
      "\u001b[34mTraining:  90%|█████████ | 9/10 [16:25<01:48, 108.55s/it]\u001b[0m\n",
      "\u001b[34mEpoch 9: train_loss = 416.370436\u001b[0m\n",
      "\u001b[34mval_loss=27.939347;\u001b[0m\n",
      "\u001b[34mTraining: 100%|██████████| 10/10 [18:13<00:00, 108.48s/it]\u001b[0m\n",
      "\u001b[34mTraining: 100%|██████████| 10/10 [18:13<00:00, 109.38s/it]\u001b[0m\n",
      "\u001b[34mTraining complete.\u001b[0m\n",
      "\u001b[34mINFO:__main__:Training complete.\u001b[0m\n",
      "\u001b[34mEvaluation Start\u001b[0m\n",
      "\u001b[34mINFO:__main__:Evaluation Start\u001b[0m\n",
      "\u001b[34mtest_loss=0.035008;\u001b[0m\n",
      "\u001b[34mtest_accuracy=0.8444976076555024;\u001b[0m\n",
      "\u001b[34mEvaluation complete.\u001b[0m\n",
      "\u001b[34mINFO:__main__:Evaluation complete.\u001b[0m\n",
      "\u001b[34mModel saved.\u001b[0m\n",
      "\u001b[34mINFO:__main__:Model saved.\u001b[0m\n",
      "\u001b[34m2025-11-04 21:12:48,811 sagemaker-training-toolkit INFO     Waiting for the process to finish and give a return code.\u001b[0m\n",
      "\u001b[34m2025-11-04 21:12:48,811 sagemaker-training-toolkit INFO     Done waiting for a return code. Received 0 from exiting process.\u001b[0m\n",
      "\u001b[34m2025-11-04 21:12:48,812 sagemaker-training-toolkit INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2025-11-04 21:13:08 Uploading - Uploading generated training model\n",
      "2025-11-04 21:13:08 Completed - Training job completed\n",
      "Training seconds: 1404\n",
      "Billable seconds: 1404\n"
     ]
    }
   ],
   "source": [
    "#launch a single job\n",
    "single.fit(inputs, logs=\"All\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-04T21:14:10.336492Z",
     "iopub.status.busy": "2025-11-04T21:14:10.334196Z",
     "iopub.status.idle": "2025-11-04T22:15:59.273288Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:image_uri is not presented, retrieving image_uri based on instance_type, framework etc.\n",
      "INFO:sagemaker.image_uris:image_uri is not presented, retrieving image_uri based on instance_type, framework etc.\n",
      "WARNING:sagemaker.estimator:No finished training job found associated with this estimator. Please make sure this estimator is only used for building workflow config\n",
      "WARNING:sagemaker.estimator:No finished training job found associated with this estimator. Please make sure this estimator is only used for building workflow config\n",
      "INFO:sagemaker.image_uris:image_uri is not presented, retrieving image_uri based on instance_type, framework etc.\n",
      "INFO:sagemaker:Creating hyperparameter tuning job with name: pytorch-training-251104-2116\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................!\n"
     ]
    }
   ],
   "source": [
    "# Launch HPO tuner\n",
    "tuner.fit(inputs, wait=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-04T22:18:26.029992Z",
     "iopub.status.busy": "2025-11-04T22:18:26.029698Z",
     "iopub.status.idle": "2025-11-04T22:18:31.464716Z",
     "shell.execute_reply": "2025-11-04T22:18:31.463373Z",
     "shell.execute_reply.started": "2025-11-04T22:18:26.029968Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2025-11-04 21:51:04 Starting - Found matching resource for reuse\n",
      "2025-11-04 21:51:04 Downloading - Downloading the training image\n",
      "2025-11-04 21:51:04 Training - Training image download completed. Training in progress.\n",
      "2025-11-04 21:51:04 Uploading - Uploading generated training model\n",
      "2025-11-04 21:51:04 Completed - Resource reused by training job: pytorch-training-251104-2116-005-0cd206d9\n",
      "Best training job name: pytorch-training-251104-2116-003-f46de529\n",
      "\n",
      "Best hyperparameters:\n",
      "{'_tuning_objective_metric': '\"val_loss\"', 'batch_size': '30', 'device': '\"cuda\"', 'epochs': '6', 'image_size': '224', 'learning_rate': '0.0005854322292922792', 'num_classes': '133', 'sagemaker_container_log_level': '20', 'sagemaker_estimator_class_name': '\"PyTorch\"', 'sagemaker_estimator_module': '\"sagemaker.pytorch.estimator\"', 'sagemaker_job_name': '\"pytorch-training-2025-11-04-21-14-10-378\"', 'sagemaker_program': '\"hpo.py\"', 'sagemaker_region': '\"us-east-1\"', 'sagemaker_submit_directory': '\"s3://sagemaker-us-east-1-106660882488/dogimages/code/20251104-201831/pytorch-training-2025-11-04-21-14-10-378/source/sourcedir.tar.gz\"'}\n"
     ]
    }
   ],
   "source": [
    "# Get the best estimators and the best HPs\n",
    "\n",
    "best_estimator = tuner.best_estimator()\n",
    "\n",
    "# Get the hyperparameters of the best trained model\n",
    "print(\"Best training job name:\", best_estimator.latest_training_job.name)\n",
    "print(\"\\nBest hyperparameters:\")\n",
    "print(best_estimator.hyperparameters())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Profiling and Debugging\n",
    "In this step, I fine-tuned the model using the best hyperparameters identified from hyperparameter tuning.The train_model.py script was used to configure SageMaker Debugger and Profiler for monitoring.A DebuggerHookConfig was added with save intervals for training and evaluation metrics.\n",
    "Profiler configuration tracked system metrics every 500 ms for CPU, GPU, and memory usage.\n",
    "Rules were added to detect vanishing gradients, overfitting, overtraining, and poor initialization.\n",
    "The ProfilerReport rule automatically generated detailed performance summaries.\n",
    "Debugger hooks collected losses, gradients, and weights to analyze model convergence.\n",
    "All profiling and debugging data were stored in S3 for reproducibility and further analysis.\n",
    "This setup ensures the final model is not only accurate but also computationally efficient and stable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-04T23:01:50.239569Z",
     "iopub.status.busy": "2025-11-04T23:01:50.239140Z",
     "iopub.status.idle": "2025-11-04T23:01:50.251422Z",
     "shell.execute_reply": "2025-11-04T23:01:50.247546Z",
     "shell.execute_reply.started": "2025-11-04T23:01:50.239534Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'num_classes': 133, 'image_size': 224, 'device': '\"cuda\"', 'epochs': 6, 'batch_size': 30, 'learning_rate': 0.0005854322292922792}\n"
     ]
    }
   ],
   "source": [
    "# Choose the best hyperparameters\n",
    "\n",
    "best_hps = best_estimator.hyperparameters()\n",
    "\n",
    "# Fixed (dataset/model-specific)\n",
    "num_classes = int(best_hps.get('num_classes'))\n",
    "image_size  = int(best_hps.get('image_size'))\n",
    "device      = str(best_hps.get('device'))\n",
    "\n",
    "# Tuned values from the best estimator\n",
    "\n",
    "epochs        = int(best_hps.get('epochs'))\n",
    "batch_size    = int(best_hps.get('batch_size'))\n",
    "learning_rate = float(best_hps.get('learning_rate'))\n",
    "\n",
    "best_hyperparameters={\n",
    "        \"num_classes\":   num_classes,\n",
    "        \"image_size\":    image_size,\n",
    "        \"device\":        device,\n",
    "        \"epochs\":        epochs,\n",
    "        \"batch_size\":    batch_size,\n",
    "        \"learning_rate\": learning_rate,\n",
    "    }\n",
    "\n",
    "print(best_hyperparameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-04T23:21:55.997330Z",
     "iopub.status.busy": "2025-11-04T23:21:55.996770Z",
     "iopub.status.idle": "2025-11-04T23:21:56.004244Z",
     "shell.execute_reply": "2025-11-04T23:21:56.002733Z",
     "shell.execute_reply.started": "2025-11-04T23:21:55.997215Z"
    }
   },
   "outputs": [],
   "source": [
    "# Set up debugging and profiling rules and hooks\n",
    "debugger_hook_config = DebuggerHookConfig(\n",
    "    hook_parameters={\n",
    "        \"train.save_interval\": \"100\",  \n",
    "        \"eval.save_interval\": \"10\"     \n",
    "    }\n",
    ")\n",
    "\n",
    "profiler_config = ProfilerConfig(system_monitor_interval_millis=500)\n",
    "rules = [\n",
    "    # Profiler rule\n",
    "    ProfilerRule.sagemaker(rule_configs.ProfilerReport()),\n",
    "\n",
    "    # Debugger rules\n",
    "    Rule.sagemaker(rule_configs.vanishing_gradient()),\n",
    "    Rule.sagemaker(rule_configs.overfit()),\n",
    "    Rule.sagemaker(rule_configs.overtraining()),\n",
    "    Rule.sagemaker(rule_configs.poor_weight_initialization()),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-04T23:21:58.081313Z",
     "iopub.status.busy": "2025-11-04T23:21:58.080558Z",
     "iopub.status.idle": "2025-11-04T23:21:58.133755Z",
     "shell.execute_reply": "2025-11-04T23:21:58.132036Z",
     "shell.execute_reply.started": "2025-11-04T23:21:58.081267Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create an estimator\n",
    "\n",
    "profile_estimator = PyTorch(\n",
    "    entry_point=\"train_model.py\",\n",
    "    source_dir=\".\",\n",
    "    role=role,\n",
    "    framework_version=\"1.13\",\n",
    "    py_version=\"py39\",\n",
    "    instance_type=\"ml.g4dn.xlarge\",\n",
    "    instance_count=1,\n",
    "    output_path=output_path,\n",
    "    code_location=code_location,\n",
    "    metric_definitions=[\n",
    "        {\"Name\": \"val_loss\",      \"Regex\": r\"val_loss=([0-9.+-eE]+);\"},\n",
    "        {\"Name\": \"test_loss\",     \"Regex\": r\"test_loss=([0-9.+-eE]+);\"},\n",
    "        {\"Name\": \"test_accuracy\", \"Regex\": r\"test_accuracy=([0-9.+-eE]+);\"},\n",
    "    ],\n",
    "    debugger_hook_config=debugger_hook_config,\n",
    "    profiler_config=profiler_config,\n",
    "    rules=rules,\n",
    "    hyperparameters=best_hyperparameters,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-04T23:22:01.312876Z",
     "iopub.status.busy": "2025-11-04T23:22:01.312087Z",
     "iopub.status.idle": "2025-11-04T23:41:59.353790Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.telemetry.telemetry_logging:SageMaker Python SDK will collect telemetry to help us better understand our user's needs, diagnose issues, and deliver additional features.\n",
      "To opt out of telemetry, please disable via TelemetryOptOut parameter in SDK defaults config. For more information, refer to https://sagemaker.readthedocs.io/en/stable/overview.html#configuring-and-using-defaults-with-the-sagemaker-python-sdk.\n",
      "INFO:sagemaker.image_uris:image_uri is not presented, retrieving image_uri based on instance_type, framework etc.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n",
      "INFO:sagemaker.image_uris:image_uri is not presented, retrieving image_uri based on instance_type, framework etc.\n",
      "INFO:sagemaker:Creating training-job with name: pytorch-training-2025-11-04-23-22-01-352\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-04 23:23:57 Starting - Starting the training job\n",
      "2025-11-04 23:23:57 Pending - Training job waiting for capacity...\n",
      "2025-11-04 23:24:26 Pending - Preparing the instances for trainingVanishingGradient: InProgress\n",
      "Overfit: InProgress\n",
      "Overtraining: InProgress\n",
      "PoorWeightInitialization: InProgress\n",
      "ProfilerReport: InProgress\n",
      "...\n",
      "2025-11-04 23:25:00 Downloading - Downloading input data...............\n",
      "2025-11-04 23:27:21 Downloading - Downloading the training image...........\n",
      "2025-11-04 23:29:22 Training - Training image download completed. Training in progress..\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.9/site-packages/paramiko/pkey.py:100: CryptographyDeprecationWarning: TripleDES has been moved to cryptography.hazmat.decrepit.ciphers.algorithms.TripleDES and will be removed from this module in 48.0.0.\n",
      "  \"cipher\": algorithms.TripleDES,\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.9/site-packages/paramiko/transport.py:259: CryptographyDeprecationWarning: TripleDES has been moved to cryptography.hazmat.decrepit.ciphers.algorithms.TripleDES and will be removed from this module in 48.0.0.\n",
      "  \"class\": algorithms.TripleDES,\u001b[0m\n",
      "\u001b[34m2025-11-04 23:29:29,202 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2025-11-04 23:29:29,225 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2025-11-04 23:29:29,240 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2025-11-04 23:29:29,244 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2025-11-04 23:29:47,960 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2025-11-04 23:29:48,024 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2025-11-04 23:29:48,079 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2025-11-04 23:29:48,103 sagemaker-training-toolkit INFO     Invoking user script\u001b[0m\n",
      "\u001b[34mTraining Env:\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"training\": \"/opt/ml/input/data/training\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"current_instance_group\": \"homogeneousCluster\",\n",
      "    \"current_instance_group_hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"current_instance_type\": \"ml.g4dn.xlarge\",\n",
      "    \"distribution_hosts\": [],\n",
      "    \"distribution_instance_groups\": [],\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"batch_size\": 30,\n",
      "        \"device\": \"\\\"cuda\\\"\",\n",
      "        \"epochs\": 6,\n",
      "        \"image_size\": 224,\n",
      "        \"learning_rate\": 0.0005854322292922792,\n",
      "        \"num_classes\": 133\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"training\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"instance_groups\": [\n",
      "        \"homogeneousCluster\"\n",
      "    ],\n",
      "    \"instance_groups_dict\": {\n",
      "        \"homogeneousCluster\": {\n",
      "            \"instance_group_name\": \"homogeneousCluster\",\n",
      "            \"instance_type\": \"ml.g4dn.xlarge\",\n",
      "            \"hosts\": [\n",
      "                \"algo-1\"\n",
      "            ]\n",
      "        }\n",
      "    },\n",
      "    \"is_hetero\": false,\n",
      "    \"is_master\": true,\n",
      "    \"is_modelparallel_enabled\": null,\n",
      "    \"is_smddpmprun_installed\": true,\n",
      "    \"is_smddprun_installed\": true,\n",
      "    \"job_name\": \"pytorch-training-2025-11-04-23-22-01-352\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-1-106660882488/dogimages/code/20251104-201831/pytorch-training-2025-11-04-23-22-01-352/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"train_model\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 4,\n",
      "    \"num_gpus\": 1,\n",
      "    \"num_neurons\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"current_instance_type\": \"ml.g4dn.xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.g4dn.xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\",\n",
      "        \"topology\": null\n",
      "    },\n",
      "    \"user_entry_point\": \"train_model.py\"\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mEnvironment variables:\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"batch_size\":30,\"device\":\"\\\"cuda\\\"\",\"epochs\":6,\"image_size\":224,\"learning_rate\":0.0005854322292922792,\"num_classes\":133}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=train_model.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.g4dn.xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g4dn.xlarge\"}],\"network_interface_name\":\"eth0\",\"topology\":null}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"training\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_TYPE=ml.g4dn.xlarge\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_GROUP=homogeneousCluster\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_GROUP_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_INSTANCE_GROUPS=[\"homogeneousCluster\"]\u001b[0m\n",
      "\u001b[34mSM_INSTANCE_GROUPS_DICT={\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g4dn.xlarge\"}}\u001b[0m\n",
      "\u001b[34mSM_DISTRIBUTION_INSTANCE_GROUPS=[]\u001b[0m\n",
      "\u001b[34mSM_IS_HETERO=false\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=train_model\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=4\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=1\u001b[0m\n",
      "\u001b[34mSM_NUM_NEURONS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-east-1-106660882488/dogimages/code/20251104-201831/pytorch-training-2025-11-04-23-22-01-352/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"training\":\"/opt/ml/input/data/training\"},\"current_host\":\"algo-1\",\"current_instance_group\":\"homogeneousCluster\",\"current_instance_group_hosts\":[\"algo-1\"],\"current_instance_type\":\"ml.g4dn.xlarge\",\"distribution_hosts\":[],\"distribution_instance_groups\":[],\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"batch_size\":30,\"device\":\"\\\"cuda\\\"\",\"epochs\":6,\"image_size\":224,\"learning_rate\":0.0005854322292922792,\"num_classes\":133},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"instance_groups\":[\"homogeneousCluster\"],\"instance_groups_dict\":{\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g4dn.xlarge\"}},\"is_hetero\":false,\"is_master\":true,\"is_modelparallel_enabled\":null,\"is_smddpmprun_installed\":true,\"is_smddprun_installed\":true,\"job_name\":\"pytorch-training-2025-11-04-23-22-01-352\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-106660882488/dogimages/code/20251104-201831/pytorch-training-2025-11-04-23-22-01-352/source/sourcedir.tar.gz\",\"module_name\":\"train_model\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":1,\"num_neurons\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.g4dn.xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g4dn.xlarge\"}],\"network_interface_name\":\"eth0\",\"topology\":null},\"user_entry_point\":\"train_model.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--batch_size\",\"30\",\"--device\",\"\\\"cuda\\\"\",\"--epochs\",\"6\",\"--image_size\",\"224\",\"--learning_rate\",\"0.0005854322292922792\",\"--num_classes\",\"133\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAINING=/opt/ml/input/data/training\u001b[0m\n",
      "\u001b[34mSM_HP_BATCH_SIZE=30\u001b[0m\n",
      "\u001b[34mSM_HP_DEVICE=\"cuda\"\u001b[0m\n",
      "\u001b[34mSM_HP_EPOCHS=6\u001b[0m\n",
      "\u001b[34mSM_HP_IMAGE_SIZE=224\u001b[0m\n",
      "\u001b[34mSM_HP_LEARNING_RATE=0.0005854322292922792\u001b[0m\n",
      "\u001b[34mSM_HP_NUM_CLASSES=133\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python39.zip:/opt/conda/lib/python3.9:/opt/conda/lib/python3.9/lib-dynload:/opt/conda/lib/python3.9/site-packages\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.9 train_model.py --batch_size 30 --device \"cuda\" --epochs 6 --image_size 224 --learning_rate 0.0005854322292922792 --num_classes 133\u001b[0m\n",
      "\u001b[34m2025-11-04 23:29:48,403 sagemaker-training-toolkit INFO     Exceptions not imported for SageMaker TF as Tensorflow is not installed.\u001b[0m\n",
      "\u001b[34m[2025-11-04 23:29:50.100 algo-1:75 INFO utils.py:28] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[2025-11-04 23:29:50.615 algo-1:75 INFO profiler_config_parser.py:111] User has disabled profiler.\u001b[0m\n",
      "\u001b[34mModel creation for fine-tuning.\u001b[0m\n",
      "\u001b[34mINFO:__main__:Model creation for fine-tuning.\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\u001b[0m\n",
      "\u001b[34mDownloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\u001b[0m\n",
      "\u001b[34m0%|          | 0.00/97.8M [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34m36%|███▌      | 35.0M/97.8M [00:00<00:00, 367MB/s]\u001b[0m\n",
      "\u001b[34m72%|███████▏  | 70.0M/97.8M [00:00<00:00, 317MB/s]\u001b[0m\n",
      "\u001b[34m100%|██████████| 97.8M/97.8M [00:00<00:00, 300MB/s]\u001b[0m\n",
      "\u001b[34mModel creation complete.\u001b[0m\n",
      "\u001b[34mINFO:__main__:Model creation complete.\u001b[0m\n",
      "\u001b[34m[2025-11-04 23:29:53.547 algo-1:75 INFO json_config.py:92] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m[2025-11-04 23:29:53.548 algo-1:75 INFO hook.py:206] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[34m[2025-11-04 23:29:53.548 algo-1:75 INFO hook.py:259] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m[2025-11-04 23:29:53.549 algo-1:75 INFO state_store.py:77] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\u001b[0m\n",
      "\u001b[34m[2025-11-04 23:29:53.563 algo-1:75 INFO hook.py:561] name:fc.weight count_params:272384\u001b[0m\n",
      "\u001b[34m[2025-11-04 23:29:53.563 algo-1:75 INFO hook.py:561] name:fc.bias count_params:133\u001b[0m\n",
      "\u001b[34m[2025-11-04 23:29:53.563 algo-1:75 INFO hook.py:563] Total Trainable Params: 272517\u001b[0m\n",
      "\u001b[34mSageMaker Debugger hook registered.\u001b[0m\n",
      "\u001b[34mINFO:__main__:SageMaker Debugger hook registered.\u001b[0m\n",
      "\u001b[34mData loader creation start\u001b[0m\n",
      "\u001b[34mINFO:__main__:Data loader creation start\u001b[0m\n",
      "\u001b[34mData loader creation complete\u001b[0m\n",
      "\u001b[34mINFO:__main__:Data loader creation complete\u001b[0m\n",
      "\u001b[34mINFO:__main__:Data loader creation start\u001b[0m\n",
      "\u001b[34mINFO:__main__:Data loader creation complete\u001b[0m\n",
      "\u001b[34mData loader creation start\u001b[0m\n",
      "\u001b[34mData loader creation complete\u001b[0m\n",
      "\u001b[34mData loader creation start\u001b[0m\n",
      "\u001b[34mINFO:__main__:Data loader creation start\u001b[0m\n",
      "\u001b[34mINFO:__main__:Data loader creation complete\u001b[0m\n",
      "\u001b[34mData loader creation complete\u001b[0m\n",
      "\u001b[34mTraining start.\u001b[0m\n",
      "\u001b[34mINFO:__main__:Training start.\u001b[0m\n",
      "\u001b[34mTraining:   0%|          | 0/6 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34m[2025-11-04 23:29:54.214 algo-1:75 INFO hook.py:427] Monitoring the collections: gradients, relu_input, losses\u001b[0m\n",
      "\u001b[34m[2025-11-04 23:29:54.216 algo-1:75 INFO hook.py:491] Hook is writing from the hook with pid: 75\u001b[0m\n",
      "\u001b[34mEpoch 0: train_loss = 650.618155\u001b[0m\n",
      "VanishingGradient: InProgress\n",
      "Overfit: InProgress\n",
      "Overtraining: InProgress\n",
      "PoorWeightInitialization: IssuesFound\n",
      "\u001b[34mval_loss=32.032227;\u001b[0m\n",
      "\u001b[34mTraining:  17%|█▋        | 1/6 [01:58<09:54, 118.85s/it]\u001b[0m\n",
      "\u001b[34mEpoch 1: train_loss = 310.569841\u001b[0m\n",
      "\u001b[34mval_loss=20.335298;\u001b[0m\n",
      "\u001b[34mTraining:  33%|███▎      | 2/6 [03:43<07:21, 110.33s/it]\u001b[0m\n",
      "\u001b[34mEpoch 2: train_loss = 249.181183\u001b[0m\n",
      "\u001b[34mval_loss=16.076701;\u001b[0m\n",
      "\u001b[34mTraining:  50%|█████     | 3/6 [05:31<05:28, 109.57s/it]\u001b[0m\n",
      "\u001b[34mEpoch 3: train_loss = 217.605514\u001b[0m\n",
      "\u001b[34mval_loss=14.277149;\u001b[0m\n",
      "\u001b[34mTraining:  67%|██████▋   | 4/6 [07:16<03:35, 107.60s/it]\u001b[0m\n",
      "\u001b[34mEpoch 4: train_loss = 198.211975\u001b[0m\n",
      "\u001b[34mval_loss=12.868004;\u001b[0m\n",
      "\u001b[34mTraining:  83%|████████▎ | 5/6 [09:04<01:47, 107.72s/it]\u001b[0m\n",
      "\u001b[34mEpoch 5: train_loss = 192.897005\u001b[0m\n",
      "\u001b[34mval_loss=13.582724;\u001b[0m\n",
      "\u001b[34mTraining: 100%|██████████| 6/6 [10:48<00:00, 106.42s/it]\u001b[0m\n",
      "\u001b[34mTraining: 100%|██████████| 6/6 [10:48<00:00, 108.05s/it]\u001b[0m\n",
      "\u001b[34mINFO:__main__:Training complete.\u001b[0m\n",
      "\u001b[34mTraining complete.\u001b[0m\n",
      "\u001b[34mEvaluation Start\u001b[0m\n",
      "\u001b[34mINFO:__main__:Evaluation Start\u001b[0m\n",
      "\u001b[34mtest_loss=0.015770;\u001b[0m\n",
      "\u001b[34mtest_accuracy=0.8564593301435407;\u001b[0m\n",
      "\u001b[34mEvaluation complete.\u001b[0m\n",
      "\u001b[34mINFO:__main__:Evaluation complete.\u001b[0m\n",
      "\u001b[34mModel saved.\u001b[0m\n",
      "\u001b[34mINFO:__main__:Model saved.\u001b[0m\n",
      "\u001b[34m2025-11-04 23:40:51,140 sagemaker-training-toolkit INFO     Waiting for the process to finish and give a return code.\u001b[0m\n",
      "\u001b[34m2025-11-04 23:40:51,140 sagemaker-training-toolkit INFO     Done waiting for a return code. Received 0 from exiting process.\u001b[0m\n",
      "\u001b[34m2025-11-04 23:40:51,141 sagemaker-training-toolkit INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2025-11-04 23:41:16 Uploading - Uploading generated training model\n",
      "2025-11-04 23:41:47 Completed - Training job completed\n",
      "VanishingGradient: NoIssuesFound\n",
      "Overfit: NoIssuesFound\n",
      "Overtraining: InProgress\n",
      "PoorWeightInitialization: IssuesFound\n",
      "Training seconds: 994\n",
      "Billable seconds: 994\n"
     ]
    }
   ],
   "source": [
    "# Fit the estimator\n",
    "profile_estimator.fit(inputs, wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Plot a debugging output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO**: Is there some anomalous behaviour in your debugging output? If so, what is the error and how will you fix it?  \n",
    "**TODO**: If not, suppose there was an error. What would that error look like and how would you have fixed it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Display the profiler output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Deploying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Deploy your model to an endpoint\n",
    "\n",
    "predictor=estimator.deploy() # TODO: Add your deployment configuration like instance type and number of instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Run an prediction on the endpoint\n",
    "\n",
    "image = # TODO: Your code to load and preprocess image to send to endpoint for prediction\n",
    "response = predictor.predict(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Remember to shutdown/delete your endpoint once your work is done\n",
    "predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.g4dn.xlarge",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
